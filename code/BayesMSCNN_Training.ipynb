{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from BayesMultiScaleCNN import BayesMultiScaleCNN\n",
    "from BBBC021 import BBBC021\n",
    "from utils import confidence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    pbar = tqdm(total=len(data_loader), desc=\"Validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for input, target, _ in data_loader:\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(input)\n",
    "            _, labels = output.max(1)\n",
    "            \n",
    "            correct += labels.eq(target).sum()\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "            \n",
    "    return correct * 100 / len(data_loader.dataset)\n",
    "\n",
    "def train(data_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    beta = torch.tensor(1.0/len(data_loader)).to(device)\n",
    "    correct = 0\n",
    "    nlls = []\n",
    "    kls = []\n",
    "    pbar = tqdm(total=len(data_loader), desc=\"Loss: 0\", leave=False)\n",
    "    for input, target, _ in train_loader:\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(input)\n",
    "        nll = criterion(output, target)\n",
    "        kl = model.kl\n",
    "        elbo = nll + beta*kl\n",
    "        \n",
    "        _, labels = output.max(1)\n",
    "        correct += labels.eq(target).sum().item()\n",
    "        nlls.append(nll.item())\n",
    "        kls.append(kl.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar.set_description(f\"Loss: {elbo.item():.03f}\")\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "        \n",
    "    return nlls, kls, correct * 100 / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./LeaveOneCompoundOut\"):\n",
    "    os.mkdir(\"LeaveOneCompoundOut\")\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"softmax_1\", \"softmax_2\", \"softmax_3\",\n",
    "        \"softmax_4\", \"softmax_5\", \"softmax_6\",\n",
    "        \"softmax_7\", \"softmax_8\", \"softmax_9\",\n",
    "        \"softmax_10\", \"softmax_11\", \"softmax_12\",\n",
    "        \"moa_pred\", \"confidence\", \"site\",\n",
    "        \"well\", \"replicate\", \"plate\",\n",
    "        \"compound\", \"concentration\", \"moa\"\n",
    "    ]\n",
    ")\n",
    "df.to_csv(\"LeaveOneCompoundOut/BBBC021_LeaveOneCompoundOut.csv\")\n",
    "    \n",
    "n_epochs = 80\n",
    "lr = 1e-2\n",
    "batch_size = 32\n",
    "milestones = [60]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "moa = BBBC021().dataset.MOA.copy()\n",
    "moa.remove('null')\n",
    "compounds = list(np.unique(BBBC021(moa=moa).dataset.compounds))\n",
    "\n",
    "for compound in compounds:\n",
    "\n",
    "    save_path = f'LeaveOneCompoundOut/{compound}.pt'\n",
    "    if compound == 'mevinolin/lovastatin':\n",
    "        save_path = 'LeaveOneCompoundOut/mevinolin-lovastatin.pt'\n",
    "\n",
    "    train_compounds = compounds.copy()\n",
    "    train_compounds.remove(compound)\n",
    "    train_dataset = BBBC021(\n",
    "        moa=moa,\n",
    "        compound=train_compounds\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_dataset = BBBC021(\n",
    "        moa=moa,\n",
    "        compound=compound\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = BayesMultiScaleCNN(\n",
    "        n_outputs=len(moa)\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), \n",
    "        lr=lr\n",
    "    )\n",
    "    _, counts = np.unique(train_dataset.dataset.moa, return_counts=True)\n",
    "    weights = torch.tensor(len(train_dataset)/counts)\n",
    "    weights = weights.type(torch.FloatTensor)\n",
    "    weights = weights.to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss(\n",
    "        reduction=\"sum\",\n",
    "        weight=weights\n",
    "    )\n",
    "\n",
    "    nlls = []\n",
    "    kls = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_acc = 0\n",
    "    pbar = tqdm(total=n_epochs, desc=\"Loss: 0 | Accuracy: 0 % [0 %]\", leave=False)\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        epoch_nll, epoch_kl, train_acc = train(\n",
    "            train_loader, model, criterion, optimizer\n",
    "        )\n",
    "        val_acc = validate(val_loader, model)\n",
    "\n",
    "        if val_acc >= best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save({\n",
    "                'state_dict': model.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'train_acc': train_acc,\n",
    "                'opt_state_dict' : optimizer.state_dict(),\n",
    "                },\n",
    "                save_path\n",
    "            )\n",
    "\n",
    "        nlls.append(epoch_nll)\n",
    "        kls.append(epoch_kl)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        desc = f\"Loss: {np.mean(epoch_nll)+np.mean(epoch_kl):.03f} | \"\n",
    "        desc += f\"Accuracy: {train_acc:.02f} % [{val_acc:.02f} %]\"\n",
    "        pbar.set_description(desc)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    checkpoint = torch.load(save_path)\n",
    "    checkpoint[\"nll\"] = nlls\n",
    "    checkpoint[\"kl\"] = kls\n",
    "    checkpoint[\"train_acc\"] = train_accs\n",
    "    checkpoint[\"val_acc\"] = val_accs\n",
    "    torch.save(\n",
    "        checkpoint,\n",
    "        save_path\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    n_samples = 100\n",
    "    with torch.no_grad():\n",
    "        for input, _, metadata in val_loader:\n",
    "            input = input.to(device)\n",
    "            output_samples = np.empty((n_samples, len(input), len(moa)))\n",
    "            for j in range(n_samples):\n",
    "                output_samples[j, ...] = F.softmax(model(input), dim=1).cpu().numpy()\n",
    "\n",
    "            outputs = output_samples.mean(axis=0)\n",
    "            confidence = confidence_score(output_samples)\n",
    "            labels = np.argmax(outputs, axis=1)\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                columns=[\n",
    "                    \"softmax_1\", \"softmax_2\", \"softmax_3\",\n",
    "                    \"softmax_4\", \"softmax_5\", \"softmax_6\",\n",
    "                    \"softmax_7\", \"softmax_8\", \"softmax_9\",\n",
    "                    \"softmax_10\", \"softmax_11\", \"softmax_12\",\n",
    "                    \"moa_pred\", \"confidence\", \"site\",\n",
    "                    \"well\", \"replicate\", \"plate\",\n",
    "                    \"compound\", \"concentration\", \"moa\"\n",
    "                ],\n",
    "                index=range(len(input))\n",
    "            )\n",
    "            df.iloc[:len(input), :len(moa)] = outputs\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"moa_pred\"] = labels\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"confidence\"] = confidence\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"site\"] = metadata[0][0].numpy()\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"well\"] = metadata[0][1]\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"replicate\"] = metadata[0][2].numpy()\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"plate\"] = metadata[0][3]\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"compound\"] = metadata[1][0]\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"concentration\"] = metadata[1][1].numpy()\n",
    "            df.loc[pd.RangeIndex(0, len(input)), \"moa\"] = metadata[1][2]\n",
    "\n",
    "            df.to_csv(\n",
    "                \"LeaveOneCompoundOut/BBBC021_LeaveOneCompoundOut.csv\",\n",
    "                mode='a',\n",
    "                index=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
